# -*- coding: utf-8 -*-
"""Peopleds

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YulnBXu3kweOe1w5J7Z3Wqs73OgUM9F5
"""

# import required libraries
import numpy as np
import pandas as pd

"""Check out this link for more information about our data
http://archive.ics.uci.edu/ml/datasets/Adult
"""

# creating a list of column headers to be used for our data
column_headers = ['age', 'workclass', 'fnlwgt', 'education', 
                  'education-num', 'marital-status', 'occupation', 
'relationship', 'race', 'sex', 'capital-gain', 'capital-loss' , 
                'hours-per-week', 'native-country', 'prediction']

# load the data into a dataframe called 'df'
df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data', names=column_headers)

# show the first 5 columns of our dataframe
df.head()

# more information about our dataset
df.info()

# check the number of rows x columns in our dataset 
df.shape

# check the unique values of marital-status
df['marital-status'].unique()

# check the frequency of the uniqe values in marital-status
df['marital-status'].value_counts()

df.education.value_counts()

# view descriptive statistics for our data
df.describe(include='all')

# view the columns in our dataset
df.columns

import pandas_profiling as pp

# the profile report of our dataframe has rich insights on our dataset
pp.ProfileReport(df)

# check correlation of numerical variables against each other
df.corr()

# check the columns
df.columns

# check the row indexes (row numbers)
df.index

# get the exact values in our dataframe
df.values

df.head()

# extract row 2 to 8
df.iloc[2:9]

df.columns

# renaming a column and make changes permanent
df.rename(columns={'fnlwgt':'final_weight'}, inplace=True)
df.columns

# drop columns and make changes permanent
df.drop(['capital-gain', 'capital-loss'], axis=1, inplace=True)

df.columns

# drop duplicate values and make changes permanent
df.drop_duplicates(keep=False, inplace=True)

df.info()

# replace all question marks with null values
df.replace(" ?", np.nan, inplace=True)
df.info()

# identify all the null values per column
# not you can also use the df.info() as above to view the null values
df.isnull().sum()

# calculate the average age
avg_age = df['age'].mean()
avg_age

# replace blank values with the average age calculated above and make the changes permanent
# remember that our age column does not have null values, so running this cell won't make any change
# this is just a demonstration so that you'll know how to deal with null values in numerical variables when you get such a problem
df['age'].replace(np.nan, avg_age, inplace=True)

df.head()

df.describe()

# check the frequency of the uniqe values in workclass in percentage
df.workclass.value_counts(normalize=True)

df['workclass'].value_counts()

df.isnull().sum()

df['workclass'].unique()

# replace null values in workclass with 'Private'
df['workclass'].replace(np.nan, ' Private', inplace=True)

df.workclass.value_counts()

df['workclass'].describe(include='all')

df.describe()

df.occupation.describe(include='all')

df.occupation.value_counts()

df.info()

df.describe(include='all')

df.info()

df.columns

# create a list of categorical columns in our dataset

catcol = ['workclass', 'education','marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country', 'prediction']

# create dummy variables for all the categories listed above
# you'll notice that the number of columns have increased from 13 to 105
df = pd.get_dummies(df, catcol)

df.info()

df.columns.values

df.head()

